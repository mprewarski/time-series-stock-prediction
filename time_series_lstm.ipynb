{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4846f067-86fb-4f32-8d54-b28617cd2cf7",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1fc5f-c8ae-48fa-9d3f-b380f1fc78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from itertools import cycle\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import schedulefree\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score \n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec934625-61d3-4349-9517-88f1976429e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed for now since these models are so small they run well on CPU\n",
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available()  else 'cpu')\n",
    "#device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fbf93-7a52-47cb-92e6-047c271be1c9",
   "metadata": {},
   "source": [
    "# Import and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3039e-cce9-4b38-92af-45b905745b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.rename(columns={'Date': 'date','Open':'open','High':'high','Low':'low',\n",
    "                            'Close':'close','Adj Close':'adj_close','Volume':'volume'})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dc3c5-69ac-4300-807e-00113a2e2d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame):\n",
    "    if df.isnull().values.sum() > 0:\n",
    "        print(\"Uh oh, null values\")\n",
    "        print(df.isnull().values.sum())\n",
    "    if df.isna().values.any():\n",
    "        print(\"NA values\")\n",
    "\n",
    "    # convert date field from string to Date format\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bc5df-c4bc-4328-8d40-b7ed5387e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_open_close_prices(df:pd.DataFrame):\n",
    "    fig = px.line(maindf,\n",
    "              x=maindf['date'], \n",
    "              y=[maindf['open'],\n",
    "                maindf['close']],        \n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ef8e1-4b5d-4a3c-b822-c4df0457d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maindf = import_data(\"data/NVDA.csv\")\n",
    "#maindf = import_data(\"data/TSLA.csv\")\n",
    "maindf = import_data(\"data/AAPL.csv\")\n",
    "maindf = preprocess_data(maindf)\n",
    "plot_open_close_prices(maindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826b07a7-445d-4d99-90f5-c7ed6ddfee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df: pd.DataFrame):\n",
    "    closedf = np.array(maindf['close']).reshape(-1,1)\n",
    "    print(f\"last: {closedf[-1]}\")\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    closedf=scaler.fit_transform(np.array(closedf).reshape(-1,1))\n",
    "    print(f\"last scaled: {closedf[-1]}\")\n",
    "    return closedf, scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b18d1-8d32-49f7-8d7c-dc505e847e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data: np.array, train_pct = 0.8):\n",
    "    data_len = data.shape[0]\n",
    "    train_size = int(data_len * train_pct)\n",
    "    \n",
    "    train_data = data[0:train_size,:]\n",
    "    val_data = data[train_size:,:]\n",
    "    print(f\"train shape: {train_data.shape},  val shape: {val_data.shape}\")\n",
    "    return train_data, val_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e28ce-3494-428c-9768-937d60a39a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step - 1):\n",
    "        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    # convert to numpy arrays\n",
    "    dataX = np.array(dataX)\n",
    "    dataY = np.array(dataY)\n",
    "    # reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "    dataX = np.expand_dims(dataX, axis=2)\n",
    "    dataY = np.expand_dims(dataY, axis=1)\n",
    "    # convert to pytorch tensors\n",
    "    dataX = torch.from_numpy(dataX).type(torch.Tensor)\n",
    "    dataY = torch.from_numpy(dataY).type(torch.Tensor)\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e175d-cc2a-4110-9d60-c59db07fe210",
   "metadata": {},
   "outputs": [],
   "source": [
    "closedf, scaler = prepare_data(maindf)\n",
    "train_data, val_data = split_data(closedf)\n",
    "print(f\"last val_data: {val_data[-1]}\")\n",
    "time_step = 15\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_val, y_val = create_dataset(val_data, time_step)\n",
    "print(y_val[-1])\n",
    "print(f\"X_train shape {X_train.shape},  y_train shape {y_train.shape}\")\n",
    "print(f\"X_val shape {X_val.shape},  y_val shape {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58149f10-1895-44d5-88de-7aacc13db900",
   "metadata": {},
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1df85b-d4ca-4ebc-86a5-1b8de6cff91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_inf(model):\n",
    "    print(\"----------- model information -----------\")\n",
    "    print(model)\n",
    "    print(f\"number of layers: {len(list(model.parameters()))}\")\n",
    "    for i in range(len(list(model.parameters()))):\n",
    "        print \n",
    "        print(list(model.parameters())[i].size())\n",
    "        \n",
    "    # total parameters and trainable parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"{total_params:,} total parameters.\")\n",
    "    total_trainable_params = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"{total_trainable_params:,} training parameters.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ccddbe-76a8-4cea-b34b-506d65090c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "\n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 32, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out.size() --> 100, 10\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53adb70d-e6dd-4fa5-9aa0-4c844844672c",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca0cac-819d-4667-a144-0e981623ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimiser, num_epochs = 200):\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # Train model\n",
    "    hist = { \n",
    "        \"loss\" : np.zeros(num_epochs),\n",
    "        \"val_loss\" : np.zeros(num_epochs)\n",
    "    }\n",
    "    best_val_loss = float('inf')\n",
    "    BEST_MODEL_PATH = \"best_model.mod\"\n",
    "\n",
    "    for t in range(num_epochs):\n",
    "        # Forward pass\n",
    "        model.train()\n",
    "        optimiser.train()\n",
    "        y_train_pred = model(X_train)\n",
    "\n",
    "        loss = loss_fn(y_train_pred, y_train)\n",
    "        hist[\"loss\"][t] = loss.item()\n",
    "\n",
    "        # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        optimiser.eval()\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = loss_fn(y_val_pred, y_val)\n",
    "        hist[\"val_loss\"][t] = val_loss.item()\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        #print(f\"saving model at {t}, loss {val_loss}\")\n",
    "            torch.save({\n",
    "                'epoch': t,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimiser.state_dict(),\n",
    "                'loss': val_loss\n",
    "                }, BEST_MODEL_PATH)\n",
    "\n",
    "\n",
    "        if t % 20 == 0 and t !=0:\n",
    "            #print(\"Epoch \", t, \"train MSE: \", loss.item())\n",
    "            print(f\"Epoch {t}  train MSE {loss.item():2.5f}  val MSE {val_loss.item():2.5f}\")\n",
    "\n",
    "    print(f\"Epoch {t}  train MSE {loss.item():2.5f}  val MSE {val_loss.item():2.5f}\")\n",
    "    return model, optimiser, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7496383-1ad0-470f-a449-72e9146c776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_model(model, optimiser, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimiser.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    model.eval()\n",
    "    print(f\"Best model loaded from epoch {epoch}, loss {loss}\")\n",
    "    return model, optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c50a4e-d147-4a39-803c-d098a07332de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_training_loss(hist):\n",
    "    df = pd.DataFrame(hist)\n",
    "    fig = px.line(df, \n",
    "              y=[df['loss'],\n",
    "                 df['val_loss']],                                       \n",
    "              labels={'value':'epoch','value': 'loss'})\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c86e8-b8d6-4323-b788-7356ad2565d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "input_dim = 1\n",
    "hidden_dim = 32\n",
    "num_layers = 2 \n",
    "output_dim = 1\n",
    "torch.manual_seed(42)\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "show_model_inf(model)\n",
    "\n",
    "# train the model\n",
    "#optimiser = torch.optim.Adam(model.parameters(), lr=0.02)\n",
    "optimizer = schedulefree.AdamWScheduleFree(model.parameters(), lr=0.02)\n",
    "epochs = 600\n",
    "model, optimiser, hist = train_model(model, optimizer, num_epochs = epochs)\n",
    "show_training_loss(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2f957-a243-434f-88e8-20a4670f84cb",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8223e693-83c7-4884-9244-73dd71df6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model eval\n",
    "model, optimiser = load_best_model(model, optimiser, \"best_model.mod\")\n",
    "\n",
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model(X_train)\n",
    "val_predict=model(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15083fbc-3d13-44a1-baad-31d46a6c2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to original data form\n",
    "train_predict = scaler.inverse_transform(train_predict.detach().numpy())\n",
    "val_predict = scaler.inverse_transform(val_predict.detach().numpy())\n",
    "original_ytrain = scaler.inverse_transform(y_train.detach().numpy())\n",
    "original_yval = scaler.inverse_transform(y_val.detach().numpy()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c3317-90b8-452f-a08f-19f82603f408",
   "metadata": {},
   "source": [
    "## Compare original closing prices with predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87149c23-3604-46e0-bc59-7949b4487176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "\n",
    "look_back=time_step\n",
    "trainPredictPlot = np.empty_like(closedf)\n",
    "trainPredictPlot[:,:] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "print(\"Train predicted data: \", trainPredictPlot.shape)\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(closedf)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(closedf)-1, :] = val_predict\n",
    "print(\"Test predicted data: \", testPredictPlot.shape)\n",
    "\n",
    "names = cycle(['Original close price','Train predicted close price','Test predicted close price'])\n",
    "\n",
    "\n",
    "plotdf = pd.DataFrame({'date': maindf['date'],\n",
    "                       'original_close': maindf['close'],\n",
    "                      'train_predicted_close': trainPredictPlot.reshape(1,-1)[0].tolist(),\n",
    "                      'test_predicted_close': testPredictPlot.reshape(1,-1)[0].tolist()})\n",
    "\n",
    "fig = px.line(plotdf,x=plotdf['date'], y=[plotdf['original_close'],plotdf['train_predicted_close'],\n",
    "                                          plotdf['test_predicted_close']],\n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "fig.update_layout(title_text='Comparision between original close price vs predicted close price',\n",
    "                  plot_bgcolor='white', font_size=15, font_color='black', legend_title_text='Close Price')\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))\n",
    "\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.update_yaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57d016-4f7c-4dfb-b2e5-aa54f6ee86aa",
   "metadata": {},
   "source": [
    "## For fun lets predict the next 20 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47c698-ac2b-4b4d-acb0-b79c21930161",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_days = 20\n",
    "# store last 15 test samples in a list\n",
    "x_input_list = list(closedf[-time_step:].squeeze())\n",
    "preds = np.zeros(pred_days)\n",
    "\n",
    "for i in range(pred_days):\n",
    "    # convert the input list to a tensor of the correct dimensions\n",
    "    x_input = torch.FloatTensor(x_input_list).unsqueeze(dim=0).unsqueeze(dim=2)\n",
    "    # make a prediction\n",
    "    yhat = model(x_input)\n",
    "    # convert the tensor back to float\n",
    "    yhat_float = float(yhat.detach().numpy()[0][0])\n",
    "    preds[i] = yhat_float\n",
    "    # remove the first element of the list and add the prediction\n",
    "    x_input_list = x_input_list[1:]\n",
    "    x_input_list.append(yhat_float)\n",
    "\n",
    "\n",
    "preds_next_20 = scaler.inverse_transform(preds.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d697b-1f3c-4eee-9087-8ff0e1333d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_20 = np.zeros(pred_days * 2)\n",
    "prev_20[:] = np.nan\n",
    "prev_20[:pred_days] = maindf['close'][-pred_days:].squeeze()\n",
    "next_20 = np.zeros(pred_days * 2)\n",
    "next_20[:] = np.nan\n",
    "next_20[pred_days:] = preds_next_20\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"last 20\" : prev_20,\n",
    "    \"next 20\" : next_20\n",
    "})\n",
    "\n",
    "fig = px.line(df, y=[df['last 20'],\n",
    "                     df['next 20']],\n",
    "              labels={'value':'Stock price','date': 'Date'})\n",
    "\n",
    "fig.update_xaxes(showgrid=True)\n",
    "fig.update_yaxes(showgrid=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3cbf3a-b2d1-464e-96f3-30711d780a19",
   "metadata": {},
   "source": [
    "## Take a look at several standard metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3ec96-5758-4137-a4eb-3c40d222b19a",
   "metadata": {},
   "source": [
    "### RMSE, MSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86146fdf-d3d5-4e42-9c76-0112268dc0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrices RMSE, MSE and MAE\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Train data RMSE: \", math.sqrt(mean_squared_error(original_ytrain,train_predict)))\n",
    "print(\"Train data MSE: \", mean_squared_error(original_ytrain,train_predict))\n",
    "print(\"Train data MAE: \", mean_absolute_error(original_ytrain,train_predict))\n",
    "print(\"-------------------------------------------------------------------------------------\")\n",
    "print(\"Val data RMSE: \", math.sqrt(mean_squared_error(original_yval,val_predict)))\n",
    "print(\"Val data MSE: \", mean_squared_error(original_yval,val_predict))\n",
    "print(\"Val data MAE: \", mean_absolute_error(original_yval,val_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e45d1-3cf3-4dac-9e5f-c57f4df80fc5",
   "metadata": {},
   "source": [
    "### R-squared (R2) \n",
    "is a statistical measure that represents the proportion of the variance for a dependent variable thats \n",
    "explained by an independent variable or variables in a regression model.\n",
    "\n",
    "1 = Best\n",
    "\n",
    "0 or < 0 = worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54e740-aef6-4772-88a4-e10636534b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#R-squared (R2) is a statistical measure that represents the proportion of the variance for a dependent variable thats \n",
    "#explained by an independent variable or variables in a regression model.\n",
    "#\n",
    "# 1 = Best\n",
    "# 0 or < 0 = worse\n",
    "print(\"--------- R2 score ------------------------------------------------------------------\")\n",
    "print(\"Train data R2 score:\", r2_score(original_ytrain, train_predict))\n",
    "print(\"Val data R2 score:\", r2_score(original_yval, val_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e869f1-cb0d-47eb-b674-c6c76c82f1a4",
   "metadata": {},
   "source": [
    "### Explained variance regression score\n",
    "The explained variance score explains the dispersion of errors of a given dataset, and the formula is written as follows: Here, and Var(y) is the variance of prediction errors and actual values respectively. Scores close to 1.0 are highly desired, indicating better squares of standard deviations of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de394573-1c8a-43a9-bdc9-f9d890008761",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data explained variance regression score:\", explained_variance_score(original_ytrain, train_predict))\n",
    "print(\"Test data explained variance regression score:\", explained_variance_score(original_yval, val_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f8bdc-0957-441c-93fd-f883d4ed0a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6168d0-d59b-406e-9f21-4e0c48fad42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data explained variance regression score:\", explained_variance_score(original_ytrain, train_predict))\n",
    "print(\"Test data explained variance regression score:\", explained_variance_score(original_yval, val_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda6bcc-0912-4d0f-947e-2b6c69cf9cd5",
   "metadata": {},
   "source": [
    "## Additional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d7891-1e0f-4dc2-b8c7-fe5890fadb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test = original_yval.squeeze()\n",
    "pred_test = val_predict.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77a885-cb7b-48b9-b421-70b0561bfb8c",
   "metadata": {},
   "source": [
    "### holding through the test period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408b6c6-4d15-4e66-8aef-4a2424baa7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_value = orig_test[-1] - orig_test[0]\n",
    "hold_change = hold_value * 100 / orig_test[0]\n",
    "print(f\"value change {hold_value:.2f}, percent change {hold_change:.2f}, num days {len(orig_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b0338-8b9d-44aa-b591-859d62934a07",
   "metadata": {},
   "source": [
    "### going long/short on the next day from the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550b041-e366-4bfc-81ca-e4eae3e97a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = 0\n",
    "for i in range(len(pred_test)):\n",
    "    if i == 0: continue\n",
    "    if pred_test[i] > orig_test[i-1]:\n",
    "        value += orig_test[i] - orig_test[i-1]\n",
    "    else:\n",
    "        value -= (orig_test[i] - orig_test[i-1])\n",
    "\n",
    "percent = value * 100 / orig_test[0]\n",
    "print(f\"value change {value:.2f}, percent change {percent:.2f}, num days {len(orig_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9a284-baea-4e53-b794-472dffafbcef",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb681b8-8a5d-4539-a97a-1f33bf7b80c7",
   "metadata": {},
   "source": [
    "The results look fairly interesting. In this instance the model seems to do fairly well and outperforms the buy and hold method through the test period. I wouldn't put any real money in this yet.\n",
    " 1. The comparison assumes you could buy or short the stock on the previous days close and sell it at the next days close.\n",
    " 2. I'm not really sure the best or most realistic way to evaluate a model's performance for financial prediction. Essentially the investor wants to achieve alpha or outperformance.\n",
    " 3. The model performs pretty well in this instance, but I've seen instances where it does poorly.\n",
    "\n",
    "There are many things different things to try.\n",
    " 1. A larger or deeper LSTM model.\n",
    " 2. Train on more data.\n",
    " 3. Use longer or shorter periods than the 15 day sequence for training.\n",
    " 4. Use more variables than just closing price.\n",
    "\n",
    "It also might be interesting to\n",
    " 1. See how well this model does on other stocks.\n",
    " 2. Train a base model on several different stocks and see if finetuning for individual stocks goes much faster.\n",
    " 3. Try to quantify how well the metrics like the R2 score translates to performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593977e-2f95-459f-a812-8488b01df22f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
